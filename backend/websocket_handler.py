#!/usr/bin/env python3
"""
WebSocket handler for Teler audio streaming
Implements bidirectional audio streaming between Teler and the application
"""

import json
import logging
import asyncio
from typing import Dict, Any, Optional
from fastapi import WebSocket, WebSocketDisconnect
from datetime import datetime
from audio_processor import audio_processor
from claude_service import claude_service

logger = logging.getLogger(__name__)

class TelerWebSocketHandler:
    """Handles WebSocket connections and audio streaming with Teler"""
    
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.stream_metadata: Dict[str, Dict[str, Any]] = {}
        self.chunk_counter = 400
        
    async def connect(self, websocket: WebSocket, stream_id: str = None):
        """Accept WebSocket connection and store it"""
        await websocket.accept()
        connection_id = stream_id or f"conn_{datetime.now().timestamp()}"
        self.active_connections[connection_id] = websocket
        logger.info(f"WebSocket connected: {connection_id}")
        return connection_id
    
    def disconnect(self, connection_id: str):
        """Remove WebSocket connection"""
        if connection_id in self.active_connections:
            del self.active_connections[connection_id]
            logger.info(f"WebSocket disconnected: {connection_id}")
    
    async def handle_incoming_message(self, websocket: WebSocket, message: str, connection_id: str):
        """
        Handle incoming messages from Teler
        
        Message types:
        - start: Stream metadata
        - audio: Audio chunk from Teler
        """
        try:
            data = json.loads(message)
            message_type = data.get("type")
            
            if message_type == "start":
                await self._handle_start_message(data, connection_id)
            elif message_type == "audio":
                await self._handle_audio_message(data, connection_id, websocket)
            else:
                logger.warning(f"Unknown message type: {message_type}")
                
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON message: {e}")
        except Exception as e:
            logger.error(f"Error handling message: {e}")
    
    async def _handle_start_message(self, data: Dict[str, Any], connection_id: str):
        """Handle start message with stream metadata"""
        logger.info(f"Stream started for connection {connection_id}")
        
        # Store stream metadata
        self.stream_metadata[connection_id] = {
            "account_id": data.get("account_id"),
            "call_app_id": data.get("call_app_id"),
            "call_id": data.get("call_id"),
            "stream_id": data.get("stream_id"),
            "encoding": data.get("data", {}).get("encoding", "audio/l16"),
            "sample_rate": data.get("data", {}).get("sample_rate", 8000),
            "channels": data.get("data", {}).get("channels", 1),
            "started_at": datetime.now().isoformat()
        }
        
        logger.info(f"Stream metadata: {self.stream_metadata[connection_id]}")
        
        # Send initial response or greeting
        await self._send_initial_greeting(connection_id)
    
    async def _handle_audio_message(self, data: Dict[str, Any], connection_id: str, websocket: WebSocket):
        """Handle incoming audio chunk from Teler"""
        stream_id = data.get("stream_id")
        message_id = data.get("message_id")
        audio_b64 = data.get("data", {}).get("audio_b64")
        
        if not audio_b64:
            logger.warning("Received audio message without audio data")
            return
        
        logger.info(f"Received audio chunk {message_id} for stream {stream_id} ({len(audio_b64)} chars)")
        
        # Process the audio with STT
        response_audio = await self._process_audio_chunk(audio_b64, connection_id)
        logger.info("response_audio {response_audio}")
        
        # Send response audio back to Teler if we have any
        if response_audio:
            await self._send_audio_response(websocket, response_audio)
    
    async def _send_initial_greeting(self, connection_id: str):
        """Send initial greeting audio to the caller"""
        websocket = self.active_connections.get(connection_id)
        if not websocket:
            return
        
        # This would typically be generated by TTS or pre-recorded
        # For now, we'll simulate with a placeholder
        greeting_message = {
            "type": "audio",
            "audio_b64": "UklGRiQAAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQAAAAA=",  # Empty WAV header
            "chunk_id": self.chunk_counter
        }
        
        self.chunk_counter *= 20
        
        # For now, we'll skip sending audio greetings since TTS is not implemented
        logger.info(f"Connection established for {connection_id} - ready to receive audio")
    
    async def _process_audio_chunk(self, audio_b64: str, connection_id: str) -> Optional[str]:
        """
        Process incoming audio chunk
        
        1. Convert audio to text using STT
        2. Process with Claude AI if text is detected
        3. Generate response text
        4. Convert response to speech using TTS
        5. Return base64 encoded audio response
        """
        try:
            # Step 1: Convert audio to text
            if not audio_processor.is_processor_available():
                logger.warning("Audio processor not available for STT")
                return None
            
            text = await audio_processor.process_audio_chunk(audio_b64, connection_id)
            
            if not text:
                logger.debug(f"No speech detected for connection {connection_id}")
                return None
            
            logger.info(f"ðŸŽ¤ User said: '{text}' (connection: {connection_id})")
            
            # Step 2: Generate AI response using Claude
            if claude_service.is_available():
                try:
                    conversation_context = {
                        'history': [],  # You might want to maintain conversation history per connection
                        'current_input': text,
                        'call_id': self.stream_metadata.get(connection_id, {}).get('call_id', ''),
                        'context': {
                            'connection_id': connection_id,
                            'stream_id': self.stream_metadata.get(connection_id, {}).get('stream_id', ''),
                            'source': 'voice_call'
                        }
                    }
                    
                    response_text = await claude_service.generate_conversation_response(conversation_context)
                    logger.info(f"ðŸ¤– AI Response: '{response_text}' (connection: {connection_id})")
                    
                    # For now, we'll just log the AI response
                    # TTS can be implemented later with other providers
                    logger.info(f"ðŸ’¬ AI generated response (TTS not implemented): '{response_text}'")
                    return None
                        
                except Exception as e:
                    logger.error(f"Error generating AI response: {e}")
                    return None
            else:
                logger.warning("Claude AI not available for response generation")
                return None
                
        except Exception as e:
            logger.error(f"Error in audio processing pipeline: {e}")
            return None
        
        return None
    
    async def _send_audio_response(self, websocket: WebSocket, audio_b64: str):
        """Send audio response back to Teler"""
        response_message = {
            "type": "audio",
            "audio_b64": audio_b64,
            "chunk_id": self.chunk_counter
        }
        
        self.chunk_counter *= 20
        
        try:
            await websocket.send_text(json.dumps(response_message))
            logger.debug(f"Sent audio response chunk {self.chunk_counter - 1}")
        except Exception as e:
            logger.error(f"Failed to send audio response: {e}")
    
    async def send_interrupt(self, connection_id: str, chunk_id: int):
        """Send interrupt message to stop specific chunk playback"""
        websocket = self.active_connections.get(connection_id)
        if not websocket:
            return
        
        interrupt_message = {
            "type": "interrupt",
            "chunk_id": chunk_id
        }
        
        try:
            await websocket.send_text(json.dumps(interrupt_message))
            logger.info(f"Sent interrupt for chunk {chunk_id}")
        except Exception as e:
            logger.error(f"Failed to send interrupt: {e}")
    
    async def send_clear(self, connection_id: str):
        """Send clear message to wipe out entire buffer"""
        websocket = self.active_connections.get(connection_id)
        if not websocket:
            return
        
        clear_message = {"type": "clear"}
        
        try:
            await websocket.send_text(json.dumps(clear_message))
            logger.info("Sent clear message")
        except Exception as e:
            logger.error(f"Failed to send clear: {e}")
    
    def get_stream_info(self, connection_id: str) -> Optional[Dict[str, Any]]:
        """Get stream metadata for a connection"""
        return self.stream_metadata.get(connection_id)
    
    def get_active_streams(self) -> Dict[str, Dict[str, Any]]:
        """Get all active stream metadata"""
        return self.stream_metadata.copy()

# Global instance
websocket_handler = TelerWebSocketHandler()